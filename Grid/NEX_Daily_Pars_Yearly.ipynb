{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdZgJQwV6IHQl/W9Kx9am4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hmARSvRRmTgQ","executionInfo":{"status":"ok","timestamp":1707587947735,"user_tz":420,"elapsed":198,"user":{"displayName":"Andrew Fullhart","userId":"10918403777587533818"}}},"outputs":[],"source":["%reset -f"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import ee\n","ee.Authenticate()\n"],"metadata":{"id":"6IRhz5sqnLXM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707587977665,"user_tz":420,"elapsed":28539,"user":{"displayName":"Andrew Fullhart","userId":"10918403777587533818"}},"outputId":"27dcb42d-2850-452d-e1e9-5c75a13a1feb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import ee\n","\n","ee.Initialize(project='ee-andrewfullhart')\n","\n","ic = ee.ImageCollection('NASA/NEX-GDDP')\n","\n","study_area = ee.FeatureCollection('users/andrewfullhart/SW_Study_Area')\n","\n","ndays_months = ee.List([31, 28.25, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n","order_months = ee.List([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n","months_index_global = ee.List.sequence(0, order_months.size().subtract(1))\n","\n","\n","\n","#inFILE = '/content/drive/My Drive/Colab Notebooks/GHCN_Historical_Annual_Mean_MEANP_Trends_Results.csv'\n","\n","#with open(inFILE) as f:\n","#  lines = f.readlines()\n","\n","#points_ft_list = ee.List([])\n","#for line in lines[1:]:\n","#  row = line.strip('\\n').split(',')\n","#  lon = float(row[1])\n","#  lat = float(row[2])\n","#  ft = ee.Feature(None, {}).setGeometry(ee.Geometry.Point(lon, lat))\n","#  points_ft_list = points_ft_list.add(ft)\n","#points_fc = ee.FeatureCollection(points_ft_list)\n","\n","first_im = ic.first()\n","points_fc = first_im.sample(region=study_area, geometries=True)\n","#points_fc = ee.FeatureCollection(points_fc.toList(points_fc.size()).slice(0, 10))\n","points_fc_list = points_fc.toList(points_fc.size())\n","\n","\n","\n","start_year = 2014\n","end_year = 2099\n","years_list_global = ee.List.sequence(start_year, end_year)\n","years_index_global = ee.List.sequence(0, years_list_global.size().subtract(1))\n","\n","def pointlabel_fn(point):\n","  point = ee.Feature(point).geometry()\n","  a_strng = ee.Number(point.coordinates().get(0)).format('%.3f')\n","  b_strng = ee.String('_')\n","  c_strng = ee.Number(point.coordinates().get(1)).format('%.3f')\n","  point_strng = a_strng.cat(b_strng).cat(c_strng)\n","  point_strng = point_strng.replace('\\\\.', '_', 'g').slice(1)\n","  return point_strng\n","\n","\n","point_labels_global = points_fc.toList(points_fc.size()).map(pointlabel_fn);\n","point_index_global = ee.List.sequence(0, point_labels_global.size().subtract(1));\n","\n","modelfilter = ee.Filter.Or(\n","              ee.Filter.eq('scenario', 'historical'),\n","              ee.Filter.eq('scenario', 'rcp45'))\n","ic = ic.filter(modelfilter)\n","ic = ic.filter(ee.Filter.eq('model', 'CCSM4')).select('pr')\n","\n","\n","global_years_list = ee.List.sequence(start_year, end_year)\n","\n","for year in global_years_list.getInfo():\n","\n","  start_year = year\n","  end_year = year\n","  years_list = ee.List.sequence(start_year, end_year)\n","  years_index = ee.List.sequence(0, years_list.size().subtract(1))\n","\n","  def year_fn(year):\n","    year = ee.Number(year)\n","    start = ee.Date.fromYMD(ee.Number(year), 1, 1)\n","    end = ee.Date.fromYMD(ee.Number(year).add(1), 1, 1)\n","    year_ic = ic.filterDate(start, end)\n","\n","    def month_fn(month):\n","      month = ee.Number(month)\n","      monthfilter = ee.Filter.calendarRange(month, month, 'month')\n","      month_ic = year_ic.filter(monthfilter)\n","\n","      def point_fn(point):\n","        point = ee.Feature(point).geometry()\n","        data_list = month_ic.getRegion(point, 500).slice(1)\n","\n","        def feature_fn(l):\n","          l = ee.List(l)\n","          date_str = ee.String(ee.String(l.get(0)).split('_').get(-1))\n","          year = ee.Number(date_str.slice(0, 4))\n","          month = ee.Number(date_str.slice(4, 6))\n","          prcp = ee.Number(l.get(4))\n","          prop_dict = {'precip':prcp}\n","          point_ft = ee.Feature(None, prop_dict)\n","          return point_ft\n","\n","        data_fc = ee.FeatureCollection(data_list.map(feature_fn))\n","        nonzero_fc = data_fc.filter(ee.Filter.gt('precip', 0))\n","        nonzero_list = ee.List(nonzero_fc.reduceColumns(ee.Reducer.toList(), ['precip']).get('list'))\n","        ndays = ee.Number(nonzero_list.size())\n","        nonzero_list = ee.List(ee.Algorithms.If(nonzero_list.size().gt(0), ee.Array(nonzero_list).multiply(ee.List.repeat(86400, nonzero_list.size())).toList(), ee.List([0.])))\n","        mean = ee.Number(nonzero_list.reduce(ee.Reducer.mean()))\n","        stdDev = ee.Number(nonzero_list.reduce(ee.Reducer.stdDev()))\n","        skew = ee.Number(nonzero_list.reduce(ee.Reducer.skew()))\n","\n","        def devSqr_fn(x):\n","          x = ee.Number(x)\n","          sqr = x.subtract(mean).pow(2)\n","          return sqr\n","\n","        devSqr = nonzero_list.map(devSqr_fn).reduce(ee.Reducer.sum())\n","\n","        def devCub_fn(x):\n","          x = ee.Number(x)\n","          cub = x.subtract(mean).pow(3)\n","          return cub\n","\n","        devCub = nonzero_list.map(devCub_fn).reduce(ee.Reducer.sum())\n","\n","        number_ft = ee.Feature(None, {'mean':mean, 'sdev':stdDev, 'skew':skew, 'ndays':ndays, 'devSqr':devSqr, 'devCub':devCub})\n","        return number_ft\n","\n","      means_fc = ee.FeatureCollection(points_fc.map(point_fn))\n","      return means_fc\n","\n","    means_fc = ee.FeatureCollection(order_months.map(month_fn))\n","    return means_fc\n","\n","  nested_fc = ee.FeatureCollection(years_list.map(year_fn))\n","  nested_fc_list = nested_fc.toList(years_list.size())\n","\n","  def year_flatten_fn(year_i):\n","    year_i = ee.Number(year_i)\n","    year = years_list.get(year_i)\n","    month_fc_list = ee.FeatureCollection(nested_fc_list.get(year_i)).toList(order_months.size())\n","\n","    def month_flatten_fn(month_i):\n","      month = ee.Number(month_i).add(1)\n","      subpoints_fc_list = ee.FeatureCollection(month_fc_list.get(month_i)).toList(points_fc.size())\n","\n","      def point_flatten_fn(point_i):\n","        point_i = ee.Number(point_i)\n","        point_ft = ee.Feature(subpoints_fc_list.get(point_i))\n","        point_label = ee.String(point_labels_global.get(point_i))\n","        mean = point_ft.get('mean')\n","        sdev = point_ft.get('sdev')\n","        skew = point_ft.get('skew')\n","        ndays = point_ft.get('ndays')\n","        devSqr = point_ft.get('devSqr')\n","        devCub = point_ft.get('devCub')\n","        prop_dict = {'point':point_label, 'year':year, 'month':month, 'mean':mean, 'sdev':sdev, 'skew':skew, 'ndays':ndays, 'devSqr':devSqr, 'devCub':devCub}\n","        return ee.Feature(None, prop_dict)\n","\n","      subflat_fc = ee.FeatureCollection(point_index_global.map(point_flatten_fn))\n","      return subflat_fc\n","\n","    flat_fc = ee.FeatureCollection(months_index_global.map(month_flatten_fn)).flatten()\n","    return flat_fc\n","\n","\n","  out_fc = ee.FeatureCollection(years_index.map(year_flatten_fn)).flatten()\n","\n","\n","  taskA = ee.batch.Export.table.toDrive(collection=out_fc,\n","                              folder='GEE_Downloads',\n","                              description='NEX_Daily_Pars_Yearly_MEAN_{}'.format(year),\n","                              selectors=['point', 'year', 'month', 'mean'])\n","\n","  taskA.start()\n","\n","  taskB = ee.batch.Export.table.toDrive(collection=out_fc,\n","                              folder='GEE_Downloads',\n","                              description='NEX_Daily_Pars_Yearly_SDEV_{}'.format(year),\n","                              selectors=['point', 'year', 'month', 'sdev'])\n","\n","  taskB.start()\n","\n","  taskC = ee.batch.Export.table.toDrive(collection=out_fc,\n","                              folder='GEE_Downloads',\n","                              description='NEX_Daily_Pars_Yearly_SKEW_{}'.format(year),\n","                              selectors=['point', 'year', 'month', 'skew'])\n","\n","  taskC.start()\n","\n","  taskD = ee.batch.Export.table.toDrive(collection=out_fc,\n","                                folder='GEE_Downloads',\n","                                description='NEX_Daily_Pars_Yearly_NDAYS_{}'.format(year),\n","                                selectors=['point', 'year', 'month', 'ndays'])\n","\n","  taskD.start()\n","\n","  taskE = ee.batch.Export.table.toDrive(collection=out_fc,\n","                                folder='GEE_Downloads',\n","                                description='NEX_Daily_Pars_Yearly_DEVSQR_{}'.format(year),\n","                                selectors=['point', 'year', 'month', 'devSqr'])\n","\n","  taskE.start()\n","\n","  taskF = ee.batch.Export.table.toDrive(collection=out_fc,\n","                                folder='GEE_Downloads',\n","                                description='NEX_Daily_Pars_Yearly_DEVCUB_{}'.format(year),\n","                                selectors=['point', 'year', 'month', 'devCub'])\n","\n","  taskF.start()\n","\n"],"metadata":{"id":"WBwxoxw-nM7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ASSUMES NO EXTRA FILES IN DIRECTORY\n","from collections import OrderedDict\n","import os\n","\n","inDIR = '/content/drive/My Drive/GEE_Downloads'\n","outDIR = '/content/drive/My Drive/Colab Notebooks'\n","\n","\n","inFILES = os.listdir(inDIR)\n","stats = ['MEAN', 'SDEV', 'SKEW', 'NDAYS', 'DEVSQR', 'DEVCUB']\n","file_dict = {s:[] for s in stats}\n","for stat in stats:\n","  for f in inFILES:\n","    finfo = f.split('_')\n","    if finfo[4] == stat:\n","      file_dict[stat].append(f)\n","\n","for stat in stats:\n","  file_dict[stat] = list(sorted(file_dict[stat]))\n","\n","hdr_lines = []\n","for stat in stats:\n","  with open(os.path.join(inDIR, file_dict[stat][0])) as f:\n","    lines = f.readlines()\n","  hdr_line = lines[0]\n","  hdr_lines.append(hdr_line)\n","\n","\n","\n","lines_dict = {}\n","\n","for stat in stats:\n","\n","  concat_lines = []\n","\n","  for fi in file_dict[stat]:\n","\n","    with open(os.path.join(inDIR, fi)) as f:\n","\n","      lines = f.readlines()\n","      concat_lines.extend(lines[1:])\n","\n","  stationIDs, years, months = [], [], []\n","  dummyStationID = concat_lines[0].split(',')[0]\n","  for line in concat_lines:\n","    row = line.strip('\\n').split(',')\n","    stationIDs.append(row[0])\n","    if row[0] == dummyStationID:\n","      years.append(str(int(float(row[1]))))\n","      months.append(str(int(float(row[2]))))\n","\n","  stationIDs = list(OrderedDict.fromkeys(stationIDs))\n","\n","  stationData_Dict = {iD:[] for iD in stationIDs}\n","  for i, iD in enumerate(stationIDs):\n","    j = i\n","    done = False\n","    while done == False:\n","      row = concat_lines[j].strip('\\n').split(',')\n","      data = row[3]\n","      if data == '':\n","        data = '0.'\n","      stationData_Dict[iD].append(data)\n","      j += len(stationIDs)\n","      if j > ((len(concat_lines)/len(stationIDs))*len(stationIDs))-1:\n","        done = True\n","\n","  fileName = 'NEX_Daily_Pars_Yearly_{}.csv'.format(stat)\n","\n","  with open(os.path.join(outDIR, fileName), 'w') as fo:\n","    fo.write('year,month,')\n","    fo.write(','.join([iD for iD in stationIDs]) + '\\n')\n","    for i in range(0, int(len(concat_lines)/len(stationIDs))):\n","      fo.write(years[i] + ',' + months[i] + ',')\n","      fo.write(','.join([stationData_Dict[iD][i] for iD in stationIDs]) + '\\n')\n","\n","\n"],"metadata":{"id":"lCb1lr2HhOk9","executionInfo":{"status":"ok","timestamp":1707588033899,"user_tz":420,"elapsed":54188,"user":{"displayName":"Andrew Fullhart","userId":"10918403777587533818"}}},"execution_count":3,"outputs":[]}]}